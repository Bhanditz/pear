%\documentstyle[psfig,12pt,fullpage]{article}
\documentstyle[12pt]{article}
\def\hind{\hangindent=2pc\hangafter=1}
\begin{document}
\noindent
\bigskip
{\Large {\bf Spread-Level Plots For Time Series Data}}
\bigskip
\bigskip
\bigskip
\\A new method of constructing spread-level (s-l) plots for time series
data and obtaining an estimate of a variance stabilizing power 
transformation is described.
A brief simulation experiment which demonstrates the effectiveness of
this methodology is reported.
Illustrative examples with various datasets are presented.
\bigskip
\\{\bf Key words:}
Box-Cox analysis;
Exploratory data analysis;
Nonstationarity;
Time series analysis;
Variance stablizing transformation.
\bigskip
\centerline{\bf 1. INTRODUCTION}
\bigskip
\\In this article, the use of s-l plots for detecting lack of
constant variance in a time series, $z_t,\quad t=1,2,\ldots$, is
discussed. 
The s-l analysis presented here is useful in various types of analyses
such as parametric model fitting as well as nonparametric spectral
analysis and seasonal adjustment.
It is shown that s-l plots useful in determining in
discovering lack of constant variance when it is not obvious
even in the ordinary time series plot of $z_t$ vs t.
Furthermore, the s-l analysis also provides a useful preliminary
estimate of a suitable power transformation.
Often the family of power transformations or equivalently
Box-Cox transformations can be used to stablize the variance
and generally improve other aspects of the analysis.
For data $z$ the family of Box-Cox transformations are given
by
\begin{eqnarray}
\label{eqn:1}
z^{(\lambda)}_t &=& {z^{\lambda}_t -1\over{\lambda}},
\quad \rm{if }\  \lambda\ne 0,\\
\noalign{\vskip6pt}
			&=&\log(z_t), \quad \rm{if }\  \lambda=0. 
\end{eqnarray}
In the case where the model is known, the Box-Cox
transformation can be estimated by maximum likelihood (Box and Cox, 1962).
However in the analysis of time series data, it is desirable
to estimate the power transformation prior to choosing a model or
performing the analysis
since the autocorrelation function of a stationary time series
may look quite different after making a power transformation
(Granger, 1964, p.47 and Granger and Newbold, 1976).
This means that if a suitable transformation is not chosen
initially the resulting analysis or model fitting may be incorrect.
An example where this actually occured is provided by the
model fit to the Sales of Company X by Chatfield and Prothero (1973).
Chatfield and Prothero fit a model with a log transformation and
latter these produced biased one-step ahead forecasts.
Box and Jenkins (1973) in their comments noted that if a 
power transformation with $\lambda = 0.3$ was used, then this difficulty
was surmounted.
In this case, a suitable model was found by estimating $\lambda$ by maximum
likelihood however in other
cases such as in exploratory analysis of a time series involving
smoothing, nonparametric spectral analysis or seasonal adjustment a
full parametric model is not even entertained, so the Box-Cox method
of maximum likelihood estimation is not available.


S-l plots for univariate data have been discussed by 
Mosteller and Tukey (1978), Emerson and Strenio (1983),
Emerson (1983) and Cleveland (1993, p.50).

Suppose that $z_1, z_2, \ldots, $ are successive observations
from generated by some unknown time series model. 
We have in mind a very broad class of possible models including
linear and nonlinear models as well as stationary and non-stationary
models.
Let $<\bullet>_t$ denote expectation conditional on given the
model and its parameters and data up to time $t$,
$z_1, \ldots, z_t$.
Then $\mu_{t+1} = <z_{t+1}>_t$ is the optimal minimum mean square error
forecast of $z_{t+1}$.
We can think of $\mu_t$ as the level of the time series at
time $t$.
The innovation at time $t+1$ is $z_{t+1}-\mu_{t+1}$ with variance
$\sigma_{t+1}^2$.
In practice it often appears that the innovation
variance is not constant but depends on the level.
As first shown by Bartlett (1947),
if the standard deviation depends on the mean so that
$\sigma_t \propto \mu_t^\alpha$
then using a Taylor series approximation it can be shown
that
$$\sigma_{z^{(\lambda)}_t} \propto \mu_t^{\lambda+\alpha-1}.$$
In order to achieve constant variance, we should choose
$\lambda = 1-\alpha$.

Given $n$ successive observations $z_1, z_2, \ldots, z_n$,
a approximate estimate of the level at time $t$, 
can be obtained by fitting by least squares the regression
of $z_t$ on $z_{t-1}, \ldots, z_{t-p}, \quad t=p+1,\ldots,n$
for some suitable p.
Under general conditions (Tsay and Tiao, 1984) these estimates are consistent
for nonstationary as well as stationary series.
The level at time $t$ is then estimated by the fitted value in 
this regression, denoted by $\hat z_t$ and the residual gives the
estimated innovation, denoted by $\hat a_t$.
In most cases, $p=1$ provides a suitable estimate but others values
may also be tried.
The s-l plot is then a plot of $log_2(|\hat a_t|)$ vs $log_2(\hat z_t)$.

A suitable Box-Cox transformation may be estimated from the plot
by fitting a straight line regression. 
If $\hat p$ denotes the slope of the linear regression of 
$\log_2(|\hat a_t|)$ on $log_2(\hat z_t)$ then
$\hat \lambda = 1-\hat \alpha$.
\bigskip
\centerline{\bf 2. SIMULATION EXPERIMENTS}
\bigskip
\bigskip
\centerline{\bf 3. ILLUSTRATIVE EXAMPLES}
\bigskip
\bigskip
\centerline{\bf REFERENCES}
\bigskip
\parindent 0pt

\hind
Bartlett, M.S. (1947),
``The use of transformations'', 
{\it Biometrics\/}, 3, 37--52.

\hind
Box, G.E.P. and Cox, D.R. (1964),
``Analysis of Transformations'',
{\it Journal of the Royal Statistical Society\/}, B 26, 211-252.

\hind
Box, G.E.P. and Jenkins, G.M. (1973),
Comments on
``Box-Jenkins seasonal forecasting: problems in a case study'',
by 
C. Chatfield and D.L. Prothero (1973),
{\it Journal of the Royal Statistical Society\/}, A 136, 295--308.

\hind
Box, G.E.P. and Jenkins, G.M. (1976),
{\it Time Series Analysis: Forecasting and Control\/},
San Francisco: Holden-Day.

\hind Chatfield, C. and Prothero, D.L. (1973),
``Box-Jenkins seasonal forecasting: problems in a case study'',
{\it Journal of the Royal Statistical Society\/}, A 136, 295--308.

\hind
Cleveland, W.~S. (1994),
{\it Visualizing Data\/}, Summit, New Jersey: Hobart Press.

\hind
Emerson, J.D. and Strenio, J. (1983),
``Boxplots and Batch Comparisons''
in {\it Understanding Robust and Exploratory Data Analysis\/},
Edited by D.~C. Hoaglin, F. Mosteller and J.~W. Tukey,
New York, N.Y.: Wiley.

\hind
Emerson, J.D. (1983),
``Mathematical Aspects of Transformation''
in {\it Understanding Robust and Exploratory Data Analysis\/},
Edited by D.~C. Hoaglin, F. Mosteller and J.~W. Tukey,
New York, N.Y.: Wiley.

\hind
Granger, C.W.J. (1964),
{\it Spectral Analysis of Economic Time Series\/},
Princeton, New Jersey: Princeton University Press.

\hind
Ruey S. T. and Tiao, G.C. (1984),
``Consistent estimates of autoregressive parameters and extended sample autocorrelation function 
for stationary and nonstationary ARMA models''
{\it Journal of the American Statistical Association\/}, 79, 84--96

\end{document}
%Figure 1 graphs the cumulative count of floods and the coresponding flood years.
%\begin{figure}
%\centerline{\psfig{figure=drbshh1.eps,width=4.5in,height=3in}}
%\caption{Flood years and cumulative count of years with floods}
%\end{figure}
%\begin{equation}
%\label{eqn:1}
%Y_t ~=~ S_t ~+~ {\cal E}_t
%\end{equation}
